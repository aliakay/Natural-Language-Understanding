{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU-Assignment-2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HIIf-bcybpp"
      },
      "source": [
        "\n",
        "# Trento University master of Artificial Intelligence Systems - Natural Language Understanding Course Second Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd8PEjJAyDtc"
      },
      "source": [
        "\n",
        "\n",
        "*   Student Name: Ali Akay\n",
        "*   Course: Natural Language Understanding\n",
        "\n",
        "*   Professor: [Giuseppe Riccardi](http://disi.unitn.it/~riccardi/)\n",
        "*   Lab: https://github.com/esrel/NLU.Lab.2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twI_1AYXylHj"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghj0_dyCJVC1",
        "outputId": "5e1ed6eb-fa62-46d5-d242-abb89cb3fce1"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import spacy \n",
        "import pandas as pd\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Token, Doc\n",
        "from collections import Counter\n",
        "!pip install seqeval\n",
        "from seqeval.metrics import accuracy_score\n",
        "!pip install spacy_conll"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=9ab58ea88709b0fdca687bad2eef90b760778d1e163fb427685f8c134ffdf70a\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Collecting spacy_conll\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/58/a666c5bf086d082ebd83954cadcb803e342e6ce4a8c3fd270820ce79341c/spacy_conll-2.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: spacy>=2.0 in /usr/local/lib/python3.7/dist-packages (from spacy_conll) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from spacy_conll) (20.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (56.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0->spacy_conll) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->spacy_conll) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0->spacy_conll) (3.10.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0->spacy_conll) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0->spacy_conll) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0->spacy_conll) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0->spacy_conll) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0->spacy_conll) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0->spacy_conll) (3.4.1)\n",
            "Installing collected packages: spacy-conll\n",
            "Successfully installed spacy-conll-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85k4dVe0Mz7"
      },
      "source": [
        "## Download Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtDoU6VOJ8fQ",
        "outputId": "80f85da9-1134-40c8-8b25-ae4c6da9eab8"
      },
      "source": [
        "!git clone https://github.com/esrel/NLU.Lab.2021.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLU.Lab.2021'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 67 (delta 17), reused 58 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiGvEYW2J-Qi"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/NLU.Lab.2021/src/conll2003.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkdJd0El0YKb"
      },
      "source": [
        "### **1st Problem-**  Evaluate spaCy NER on CoNLL 2003 data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKjC3yyi0mLk"
      },
      "source": [
        "Firstly I created a function from load txt file to list of sentences as dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvkd543NKAGX"
      },
      "source": [
        "def load_sentences(filepath):\n",
        "    \"\"\"\n",
        "    Load sentences (separated by newlines) from dataset\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filepath : str\n",
        "        path to corpus file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List of sentences represented as dictionaries\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    sentences, tok, pos, chunk, ne = [], [], [], [], []\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n':\n",
        "               # Sentence as a sequence of tokens, POS, chunk and NE tags\n",
        "                sentence = dict({'TOKENS' : [], 'POS' : [], 'CHUNK_TAG' : [], 'NE' : [], 'SEQ' : []})\n",
        "                sentence['TOKENS'] = tok\n",
        "                sentence['POS'] = pos\n",
        "                sentence['CHUNK_TAG'] = chunk\n",
        "                sentence['NE'] = ne\n",
        "               \n",
        "                # Once a sentence is processed append it to the list of sentences\n",
        "                sentences.append(sentence)\n",
        "               \n",
        "                # Reset sentence information\n",
        "                tok = []\n",
        "                pos= []\n",
        "                chunk = []\n",
        "                ne = []\n",
        "            else:\n",
        "                l = line.split(' ')\n",
        "               \n",
        "                # Append info for next word\n",
        "                tok.append(l[0])\n",
        "                pos.append(l[1])\n",
        "                chunk.append(l[2])\n",
        "                ne.append(l[3].strip('\\n'))\n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKwX9pzKCG8"
      },
      "source": [
        "train_data=load_sentences(\"train.txt\")\n",
        "test_data=load_sentences(\"test.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-xrDqD20-fC"
      },
      "source": [
        "As you can see we have Chunk_tag, NE, POS, SEQ and Tokens in the dic. In this assingment we are going to use only TOKEN and Named Entities Tag.We can get token and NE from dictionary to dataframe by using **convert_data_to_df()** function. In this assignment I tried to use DataFrame for understanding and process data better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cJI_VYhwoXa",
        "outputId": "a37a553b-b7d6-4e82-9ba6-9787f8b85f02"
      },
      "source": [
        "test_data[4]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CHUNK_TAG': ['B-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP'],\n",
              " 'NE': ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O'],\n",
              " 'POS': ['NNP', ',', 'NNP', 'NNP', 'NNPS', 'CD'],\n",
              " 'SEQ': [],\n",
              " 'TOKENS': ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAFnAOtKWza9"
      },
      "source": [
        "def conver_data_to_df(data):\n",
        "\n",
        "  \"\"\"\n",
        "   Parameters\n",
        "    ----------\n",
        "    data : dictionary format of data. Eg.(test_data[4])\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dataframe which include word and token.\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  test_data_sen=pd.DataFrame()\n",
        "  test_data_sen=pd.DataFrame(pd.DataFrame(data)[\"TOKENS\"][0])\n",
        "  #append tokens in dataframe\n",
        "  for i in range(len(data)):\n",
        "    b=pd.DataFrame(pd.DataFrame(data)[\"TOKENS\"][i])\n",
        "    test_data_sen=pd.concat([test_data_sen,b])\n",
        "  test_data_sen.reset_index(drop=True,inplace=True)\n",
        "  test_data_sen.columns=[\"Word\"]\n",
        "  test_data_sen=test_data_sen.apply(lambda x: x.astype(str).str.lower())\n",
        "\n",
        "  #append NE in dataframe\n",
        "  data_NE=pd.DataFrame()\n",
        "  data_NE=pd.DataFrame(pd.DataFrame(data)[\"NE\"][0])\n",
        "  for i in range(len(data)):\n",
        "    b=pd.DataFrame(pd.DataFrame(data)[\"NE\"][i])\n",
        "    data_NE=pd.concat([data_NE,b])\n",
        "  data_NE.reset_index(drop=True,inplace=True)\n",
        "  data_NE.columns=[\"NE_TAG\"]\n",
        "  #combine two dataframe\n",
        "  data_final=pd.concat([test_data_sen,data_NE],axis=1)\n",
        "  return data_final"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRrBhCnip7MK"
      },
      "source": [
        "In this assignment I only work on **\"test.txt\"**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z7l0UATRBXg"
      },
      "source": [
        "test_data_df=conver_data_to_df(test_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "HDEBePxXglgy",
        "outputId": "c85bdb3c-a4cf-4f3c-b893-38d7d4348df6"
      },
      "source": [
        "test_data_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>NE_TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soccer</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lucky</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46430</th>\n",
              "      <td>younger</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46431</th>\n",
              "      <td>brother</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46432</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46433</th>\n",
              "      <td>bobby</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46434</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46435 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word NE_TAG\n",
              "0       soccer      O\n",
              "1            -      O\n",
              "2        japan  B-LOC\n",
              "3          get      O\n",
              "4        lucky      O\n",
              "...        ...    ...\n",
              "46430  younger      O\n",
              "46431  brother      O\n",
              "46432        ,      O\n",
              "46433    bobby  B-PER\n",
              "46434        .      O\n",
              "\n",
              "[46435 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzPJ6Pp1fBfD"
      },
      "source": [
        "#train_data_df=conver_data_to_df(train_data)\n",
        "#train_data_df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onhw9bpQchBJ"
      },
      "source": [
        "#train_data_df.to_csv(\"train_data.csv\")\n",
        "#test_data_df.to_csv(\"test_data.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL43qyNq2RIq"
      },
      "source": [
        "We have to predict name entities using spacy for the first question. First we have to recreate sentences by using tokens then we have to find spacy name entities tag.I used **create_sentences_NE_data()** function to re-crate sentences from token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmzrtciLRpUy"
      },
      "source": [
        "def create_sentences_NE_data(data):\n",
        "  \"\"\"\n",
        "   Parameters\n",
        "    ----------\n",
        "    data : dictionary format of data. \n",
        "    For the sentences we use token column.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of sentences \n",
        "    list of NE\n",
        "  \"\"\"\n",
        "\n",
        "  datasentences=[]\n",
        "  for i in range(len(data)):\n",
        "    datasentences.append(' '.join(word for word in pd.DataFrame(data)[\"TOKENS\"][i])) #convert tokens to a sentence.\n",
        "  \n",
        "  data_ne=[]\n",
        "  for i in range(len(data)):\n",
        "    data_ne.append(pd.DataFrame(data)[\"NE\"][i])\n",
        "  return datasentences,data_ne"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ig1D_rYjRrW"
      },
      "source": [
        "test_data_sent,test_data_ne=create_sentences_NE_data(test_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT1A15-y7R_7"
      },
      "source": [
        "#Drop NA and null in the lists.\n",
        "test_data_sent = list(filter(None, test_data_sent))\n",
        "test_data_ne = list(filter(None, test_data_ne))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "oOKnj78Ljv1D",
        "outputId": "a1f2313f-2afe-45aa-9c43-14731168d180"
      },
      "source": [
        "test_data_sent[2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AL-AIN , United Arab Emirates 1996-12-06'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSLKvGp679Ov",
        "outputId": "c6fae340-a64a-4d17-cbd6-fec4e5836527"
      },
      "source": [
        "test_data_ne[2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pVh5P-_9Ft3",
        "outputId": "bd1733b5-1a0d-4be8-97e4-cf44ea31ded3"
      },
      "source": [
        "print(len(test_data_sent))\n",
        "print(len(test_data_ne))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3453\n",
            "3453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Qw82Qr3SVp"
      },
      "source": [
        "Using WhitespaceTokenizer, I can able to tokenize sentences same as Conll token format. Basically,tokenize a string on whitespace (space, tab, newline). In general, users should use the string split() method instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMYQL8nKntbz"
      },
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from spacy_conll import init_parser,ConllFormatter\n",
        "\n",
        "class WhitespaceTokenizer:\n",
        "    def __init__(self, vocab): self.vocab = vocab\n",
        "    def __call__(self, text):\n",
        "        words = text.split(\" \")                       \n",
        "        return Doc(self.vocab, words=words)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)\n",
        "conllformatter = ConllFormatter(nlp)\n",
        "nlp.add_pipe(conllformatter, last=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXDmFgVk3iUA"
      },
      "source": [
        "In spacy we get different labels for the NE. We should convert them the the conll format to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Ny8sD3JGKw"
      },
      "source": [
        "def replace_values_in_string(text, args_dict):\n",
        "    for key in args_dict.keys():\n",
        "        text = text.replace(key, str(args_dict[key]))\n",
        "    \n",
        "    return text\n",
        "\n",
        "dic_ne = {   \n",
        "    \"ORG\": \"ORG\",\n",
        "    \"PERSON\": \"PER\",\n",
        "    \"EVENT\": \"MISC\",\n",
        "    \"NORP\": \"MISC\",\n",
        "    \"FAC\": \"MISC\",\n",
        "    \"WORK_OF_ART\": \"MISC\",\n",
        "    \"PRODUCT\": \"MISC\",\n",
        "    \"LAW\": \"MISC\",\n",
        "    \"LANGUAGE\": \"MISC\",\n",
        "    \"DATE\": \"MISC\",\n",
        "    \"TIME\": \"MISC\",\n",
        "    \"PERCENT\": \"MISC\",\n",
        "    \"ORDINAL\": \"MISC\",\n",
        "    \"CARDINAL\":  \"MISC\",\n",
        "    \"MONEY\": \"MISC\",\n",
        "    \"QUANTITY\": \"MISC\",\n",
        "    \"GPE\": \"LOC\",\n",
        "    \"LOC\": \"LOC\"\n",
        "}\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZSvlxLlqlSK"
      },
      "source": [
        "Basically I have to empty list.Tokens added in **ent_list** for every sentences.**ent_list_sen** is used to collect token for every sentences and then appended to **ent_list**. Then I covert list to dataframe format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "xGj_gFuakY6L",
        "outputId": "99844911-0d21-42bb-c3a9-88cbfe7fe3ff"
      },
      "source": [
        "def spacy_prediction(sentences_data):\n",
        "  \"\"\"\n",
        "   Parameters\n",
        "    ----------\n",
        "    data : list of sentences. eg.(test_data_sent) \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    data frame which is include token and NE prediction fo spacy.\n",
        "  \"\"\"\n",
        "\n",
        "  #append entities in this list\n",
        "  ent_list=[]\n",
        "  for i in range(len(sentences_data)):\n",
        "    ent_list_sen=[] \n",
        "\n",
        "    text=sentences_data[i]\n",
        "    #to precise prediction I converted all sentences in lowercase\n",
        "    text=text.lower() \n",
        "    doc = nlp(text)\n",
        "    for token in doc:\n",
        "      ent_list_sen.append([token.text,token.ent_iob_ + '-' + replace_values_in_string(token.ent_type_, dic_ne)])\n",
        "      \n",
        "    ent_list.append(ent_list_sen)\n",
        "    \n",
        "  spacy_ne_pred=pd.DataFrame()\n",
        "  spacy_ne_pred=pd.DataFrame(ent_list[0])\n",
        "\n",
        "  #Creating dataframe after getting list\n",
        "  for i in range(len(ent_list)):\n",
        "    list=pd.DataFrame(ent_list[i])\n",
        "    spacy_ne_pred=pd.concat([spacy_ne_pred,list])\n",
        "  spacy_ne_pred.reset_index(drop=True,inplace=True)\n",
        "  spacy_ne_pred.columns=[\"Word\",\"NE_pred\"]\n",
        "  return spacy_ne_pred\n",
        "\n",
        "spacy_pred=spacy_prediction(test_data_sent)\n",
        "spacy_pred"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>NE_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soccer</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lucky</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46442</th>\n",
              "      <td>younger</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46443</th>\n",
              "      <td>brother</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46444</th>\n",
              "      <td>,</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46445</th>\n",
              "      <td>bobby</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46446</th>\n",
              "      <td>.</td>\n",
              "      <td>O-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46447 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word NE_pred\n",
              "0       soccer      O-\n",
              "1            -      O-\n",
              "2        japan   B-LOC\n",
              "3          get      O-\n",
              "4        lucky      O-\n",
              "...        ...     ...\n",
              "46442  younger      O-\n",
              "46443  brother      O-\n",
              "46444        ,      O-\n",
              "46445    bobby   B-PER\n",
              "46446        .      O-\n",
              "\n",
              "[46447 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J87a7chrIE0Z"
      },
      "source": [
        "#Convert \"O-\" to \"O\"\n",
        "spacy_pred['NE_pred'] = spacy_pred['NE_pred'].str.replace('O-','O')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKp8Zn1t4szv"
      },
      "source": [
        "We got our spacy prediction. As you can see two dataframe is in same format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ASZ_V_aqpEwO",
        "outputId": "11be7cb9-fbe1-41eb-a9b5-8c83b65f4c37"
      },
      "source": [
        "spacy_pred.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>NE_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soccer</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lucky</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Word NE_pred\n",
              "0  soccer       O\n",
              "1       -       O\n",
              "2   japan   B-LOC\n",
              "3     get       O\n",
              "4   lucky       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DRfQN4Nto9ZU",
        "outputId": "5257212e-6a49-43e5-a5fd-65cee5931c8f"
      },
      "source": [
        "test_data_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>NE_TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soccer</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lucky</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Word NE_TAG\n",
              "0  soccer      O\n",
              "1       -      O\n",
              "2   japan  B-LOC\n",
              "3     get      O\n",
              "4   lucky      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trhT2kFL_t2G"
      },
      "source": [
        "We have to merge on \"Word\" these two dataframe to evaluate.After merged dataset I got Token-Ne_Tag-Spacy NE Tag prediction in same dataframe. I used this dataframe to compute accuracy for the token-level evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FTKdtkrvu3wr",
        "outputId": "461342d8-56a1-4d58-9fec-806a2eaaf26c"
      },
      "source": [
        "data=pd.merge(test_data_df,spacy_pred,on=[\"Word\"]).drop_duplicates(subset=['Word'])\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "data"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>NE_TAG</th>\n",
              "      <th>NE_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soccer</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lucky</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8543</th>\n",
              "      <td>well-fancied</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8544</th>\n",
              "      <td>lanky</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8545</th>\n",
              "      <td>1966</td>\n",
              "      <td>B-MISC</td>\n",
              "      <td>I-MISC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8546</th>\n",
              "      <td>younger</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8547</th>\n",
              "      <td>bobby</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8548 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Word  NE_TAG NE_pred\n",
              "0           soccer       O       O\n",
              "1                -       O       O\n",
              "2            japan   B-LOC   B-LOC\n",
              "3              get       O       O\n",
              "4            lucky       O       O\n",
              "...            ...     ...     ...\n",
              "8543  well-fancied       O       O\n",
              "8544         lanky       O       O\n",
              "8545          1966  B-MISC  I-MISC\n",
              "8546       younger       O       O\n",
              "8547         bobby   B-PER   B-PER\n",
              "\n",
              "[8548 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "NkJlZYwISzIC",
        "outputId": "02eea184-3da9-4b53-cf7a-6a99676cd6b7"
      },
      "source": [
        "data[15:25]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>NE_TAG</th>\n",
              "      <th>NE_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>united</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>arab</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>emirates</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1996-12-06</td>\n",
              "      <td>O</td>\n",
              "      <td>B-MISC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>began</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>defence</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>their</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>asian</td>\n",
              "      <td>B-MISC</td>\n",
              "      <td>B-MISC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word  NE_TAG NE_pred\n",
              "15      united   B-LOC   B-LOC\n",
              "16        arab   I-LOC   I-LOC\n",
              "17    emirates   I-LOC   I-LOC\n",
              "18  1996-12-06       O  B-MISC\n",
              "19       began       O       O\n",
              "20         the       O       O\n",
              "21     defence       O       O\n",
              "22          of       O       O\n",
              "23       their       O       O\n",
              "24       asian  B-MISC  B-MISC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8sRoxEryvnq",
        "outputId": "4d40f8ff-f2ef-4d8d-a2e3-21b48869ffef"
      },
      "source": [
        "data.NE_TAG.unique()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-LOC', 'B-PER', 'I-PER', 'I-LOC', 'B-MISC', 'I-MISC',\n",
              "       'B-ORG', 'I-ORG'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhUu2SOS6Bhi",
        "outputId": "78984433-ff5f-44c6-e577-a1a4c060a894"
      },
      "source": [
        "data.NE_pred.unique()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER',\n",
              "       'B-ORG', 'I-ORG'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjCPMaRxnHQI"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SK8M2yM-RYz",
        "outputId": "6968a41b-97f7-483f-8ccd-1722f550fa27"
      },
      "source": [
        "print(\"Token-level Accuracy\",accuracy_score(data.NE_TAG, data.NE_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token-level Accuracy 0.6720870379036031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "W5LTa7EAeDGk",
        "outputId": "67d23760-afc4-43f9-dd33-031a433bcb57"
      },
      "source": [
        "labels_ne = data.NE_TAG.unique().tolist()\n",
        "labels_ne\n",
        "precision, recall, fscore, support = score(data.NE_TAG.tolist(), data.NE_pred.tolist())\n",
        "results_df=pd.DataFrame()\n",
        "results_df=results_df.append([labels_ne,precision, recall, fscore, support]).T\n",
        "results_df.columns=[\"Labels\",\"Precision\",\"Recall\",\"Fscore\",\"Support\"]\n",
        "results_df"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Fscore</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O</td>\n",
              "      <td>0.638655</td>\n",
              "      <td>0.484076</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-LOC</td>\n",
              "      <td>0.0789755</td>\n",
              "      <td>0.350711</td>\n",
              "      <td>0.12892</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-PER</td>\n",
              "      <td>0.510638</td>\n",
              "      <td>0.193159</td>\n",
              "      <td>0.280292</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I-PER</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.457849</td>\n",
              "      <td>0.553603</td>\n",
              "      <td>688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I-LOC</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B-MISC</td>\n",
              "      <td>0.028777</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.0495356</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I-MISC</td>\n",
              "      <td>0.350785</td>\n",
              "      <td>0.304545</td>\n",
              "      <td>0.326034</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B-ORG</td>\n",
              "      <td>0.752747</td>\n",
              "      <td>0.578873</td>\n",
              "      <td>0.654459</td>\n",
              "      <td>710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I-ORG</td>\n",
              "      <td>0.810573</td>\n",
              "      <td>0.791875</td>\n",
              "      <td>0.801115</td>\n",
              "      <td>5809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Labels  Precision    Recall     Fscore Support\n",
              "0       O   0.638655  0.484076   0.550725     314\n",
              "1   B-LOC  0.0789755  0.350711    0.12892     211\n",
              "2   B-PER   0.510638  0.193159   0.280292     497\n",
              "3   I-PER        0.7  0.457849   0.553603     688\n",
              "4   I-LOC   0.488889  0.407407   0.444444      54\n",
              "5  B-MISC   0.028777  0.177778  0.0495356      45\n",
              "6  I-MISC   0.350785  0.304545   0.326034     220\n",
              "7   B-ORG   0.752747  0.578873   0.654459     710\n",
              "8   I-ORG   0.810573  0.791875   0.801115    5809"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A_vsavRLthR"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwUZc94tLudk"
      },
      "source": [
        "### Chunk-Level Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "k-82mV7DL1xj",
        "outputId": "723aa073-8931-4815-8c2b-a937a4d80287"
      },
      "source": [
        "test_data=pd.DataFrame(test_data)\n",
        "test_data.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOKENS</th>\n",
              "      <th>POS</th>\n",
              "      <th>CHUNK_TAG</th>\n",
              "      <th>NE</th>\n",
              "      <th>SEQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, ...</td>\n",
              "      <td>[NN, :, NNP, VB, NNP, NNP, ,, NNP, IN, DT, NN, .]</td>\n",
              "      <td>[B-NP, O, B-NP, B-VP, B-NP, I-NP, O, B-NP, B-P...</td>\n",
              "      <td>[O, O, B-LOC, O, O, O, O, B-PER, O, O, O, O]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>[NNP, NNP]</td>\n",
              "      <td>[B-NP, I-NP]</td>\n",
              "      <td>[B-PER, I-PER]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
              "      <td>[NNP, ,, NNP, NNP, NNPS, CD]</td>\n",
              "      <td>[B-NP, O, B-NP, I-NP, I-NP, I-NP]</td>\n",
              "      <td>[B-LOC, O, B-LOC, I-LOC, I-LOC, O]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              TOKENS  ... SEQ\n",
              "0                                                 []  ...  []\n",
              "1                                                 []  ...  []\n",
              "2  [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, ...  ...  []\n",
              "3                                     [Nadim, Ladki]  ...  []\n",
              "4    [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]  ...  []\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgJfnRQy5O6A"
      },
      "source": [
        "For the chunk level evaluation I used conll.evaluate function. For this reason we have to get \"ref\" and \"hyp\" data in a same format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o8c-gL2Bmmn"
      },
      "source": [
        "#Collect ref data using for loop.\n",
        "test_data=test_data[[\"TOKENS\",\"NE\"]]\n",
        "ref=[]\n",
        "for i in range(len(test_data[\"TOKENS\"])):\n",
        "  text=test_data[\"TOKENS\"][i]\n",
        "  ne=test_data[\"NE\"][i]\n",
        "  a=[]\n",
        "  for j in range(len(text)):\n",
        "    a.append((text[j],ne[j]))\n",
        "  ref.append(a)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2RZcAaV-SmP"
      },
      "source": [
        "#dropping null lists\n",
        "ref = list(filter(None, ref))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo_-N8CRDEua",
        "outputId": "9af95708-2275-47db-eabe-1688d2ab9a21"
      },
      "source": [
        "ref[61]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('9.', 'O'),\n",
              " ('Johann', 'B-PER'),\n",
              " ('Gregoire', 'I-PER'),\n",
              " ('(', 'O'),\n",
              " ('France', 'B-LOC'),\n",
              " (')', 'O'),\n",
              " ('22.58', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtdYuAxFE2xp",
        "outputId": "8b0b31c4-f97b-4ef0-b3cd-0385ddd86b06"
      },
      "source": [
        "#example hyp for a sentence\n",
        "d=[]\n",
        "doc=nlp(test_data_sent[61])\n",
        "for token in doc:\n",
        "  d.append((token.text,token.ent_iob_ + '-' + replace_values_in_string(token.ent_type_, dic_ne)))\n",
        "d"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('9.', 'O-'),\n",
              " ('Johann', 'B-PER'),\n",
              " ('Gregoire', 'I-PER'),\n",
              " ('(', 'O-'),\n",
              " ('France', 'B-LOC'),\n",
              " (')', 'O-'),\n",
              " ('22.58', 'B-MISC')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0UCddjVr8xQ"
      },
      "source": [
        "With this for loop, I could able to create hyp data. Basically for every sentences I run spacy code to collect data then append it in the list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yuzXsYKcnvO"
      },
      "source": [
        "import numpy as np\n",
        "hyp=[]\n",
        "for i in range(len(test_data_sent)):\n",
        "    text=test_data_sent[i]\n",
        "    c=[]\n",
        "    doc = nlp(text)\n",
        "    for token in doc:\n",
        "        c.append((token.text,token.ent_iob_ + '-' + replace_values_in_string(token.ent_type_, dic_ne) if token.ent_type_ != \"\" else \"O\" ))\n",
        "    hyp.append(c)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7C8s8IrEyup",
        "outputId": "fc868d49-0a9f-48f9-b662-4715076dc13b"
      },
      "source": [
        "hyp[2]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AL-AIN', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('United', 'B-LOC'),\n",
              " ('Arab', 'I-LOC'),\n",
              " ('Emirates', 'I-LOC'),\n",
              " ('1996-12-06', 'B-MISC')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Sg7yuTGsrw",
        "outputId": "06244cfa-1beb-4c12-ac81-7f9a34b7debd"
      },
      "source": [
        "ref[2]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AL-AIN', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('United', 'B-LOC'),\n",
              " ('Arab', 'I-LOC'),\n",
              " ('Emirates', 'I-LOC'),\n",
              " ('1996-12-06', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9IfNSBu_bNfq",
        "outputId": "8ac501d9-cd0f-4a12-c393-b766750bb61d"
      },
      "source": [
        "import conll\n",
        "results = conll.evaluate(ref, hyp)\n",
        "\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.724</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.642</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.355</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.094</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.161</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.771</td>\n",
              "      <td>0.668</td>\n",
              "      <td>0.716</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.368</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.430</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.724  0.577  0.642  1617\n",
              "ORG    0.441  0.297  0.355  1661\n",
              "MISC   0.094  0.551  0.161   702\n",
              "LOC    0.771  0.668  0.716  1668\n",
              "total  0.368  0.518  0.430  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzPeguIDo_Do"
      },
      "source": [
        "## **2nd Problem**- Grouping of Entities. Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3zkca7GABZJ"
      },
      "source": [
        "For this question I create a function that predict entities by sentences.Then I use counter library to get frequency of the group entities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvrPtNF0R1LT",
        "outputId": "e9327ff9-6eee-407e-a86e-2fc3b218b8b2"
      },
      "source": [
        "len(test_data_sent)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuyiNTwcyJm0"
      },
      "source": [
        "Example of for loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8c1OA23T7mW",
        "outputId": "450da523-9aa2-4871-9f8f-720f709fee88"
      },
      "source": [
        "test_data_sent[:5]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .',\n",
              " 'Nadim Ladki',\n",
              " 'AL-AIN , United Arab Emirates 1996-12-06',\n",
              " 'Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .',\n",
              " 'But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers Uzbekistan .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYwn6bomx2kt"
      },
      "source": [
        "  chunk=[] \n",
        "  for i in range(len(test_data_sent[:5])):\n",
        "    doc = nlp(test_data_sent[i])\n",
        "    for nc in doc.noun_chunks: \n",
        "      c_l=[]\n",
        "      for ent in nc.ents:\n",
        "        for token in ent:\n",
        "          c_l.append(token.ent_type_ if token.ent_type_ != \"\" else \"O\" )\n",
        "    chunk.append(c_l)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkUrb8YUyaUb"
      },
      "source": [
        "In this case ['GPE', 'GPE', 'GPE'] is United Arab Emirates. [\"Date\"] is Friday in 4th sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l2VIGQxx8GJ",
        "outputId": "d9054229-bce8-4e83-da53-90973b42db61"
      },
      "source": [
        "chunk"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [], ['GPE', 'GPE', 'GPE'], ['DATE'], ['GPE']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXPWWYKDkEWg"
      },
      "source": [
        "def group_entities(sentences_data):\n",
        "  \"\"\"\n",
        "   Parameters\n",
        "    ----------\n",
        "    data : list of sentences. eg.(test_data_sent) \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of Name entities of the sentences.\n",
        "  \"\"\"\n",
        "  chunk=[] \n",
        "  for i in range(len(sentences_data)):\n",
        "    doc = nlp(sentences_data[i])\n",
        "    for nc in doc.noun_chunks: \n",
        "      c_l=[]\n",
        "      for ent in nc.ents:\n",
        "        for token in ent:\n",
        "          c_l.append(token.ent_type_ if token.ent_type_ != \"\" else \"O\" )\n",
        "    chunk.append(c_l)\n",
        "\n",
        "  #dropping nulls.\n",
        "  chunk_list = []\n",
        "  for val in chunk:\n",
        "      if val != [] :\n",
        "          chunk_list.append(val)\n",
        "  return chunk_list"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5apKZDqSM_m",
        "outputId": "d70e6760-0af8-4bd7-d958-6a3810232d8d"
      },
      "source": [
        "chunk=group_entities(test_data_sent)\n",
        "chunk[:5]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['GPE', 'GPE', 'GPE'], ['DATE'], ['GPE'], ['ORDINAL'], ['GPE']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnk9d4KjNc1F",
        "outputId": "5b0d5f5a-5baf-4193-cf25-02a17c0b5d97"
      },
      "source": [
        "from collections import Counter\n",
        "chunk_frequency = Counter(map(tuple, chunk))\n",
        "chunk_frequency.most_common(20)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('GPE',), 488),\n",
              " (('ORG',), 189),\n",
              " (('DATE',), 175),\n",
              " (('PERSON', 'PERSON'), 137),\n",
              " (('CARDINAL',), 105),\n",
              " (('PERSON',), 64),\n",
              " (('GPE', 'GPE'), 59),\n",
              " (('NORP',), 54),\n",
              " (('ORG', 'ORG'), 48),\n",
              " (('PERSON', 'PERSON', 'PERSON'), 27),\n",
              " (('ORDINAL',), 21),\n",
              " (('DATE', 'DATE'), 20),\n",
              " (('ORG', 'ORG', 'ORG', 'ORG'), 18),\n",
              " (('ORG', 'ORG', 'ORG'), 15),\n",
              " (('PERCENT', 'PERCENT'), 13),\n",
              " (('CARDINAL', 'GPE'), 12),\n",
              " (('ORG', 'ORG', 'ORG', 'ORG', 'ORG'), 11),\n",
              " (('CARDINAL', 'CARDINAL'), 9),\n",
              " (('MONEY', 'MONEY'), 9),\n",
              " (('TIME', 'TIME'), 8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxDcnc-mUX5"
      },
      "source": [
        "## **3th Problem**- One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCtxywm__DhI"
      },
      "source": [
        "For the problem I try to create logic that if we find a token with a ‘compund’ dependency, check if it is in the same entity as it’s head; if not, create a new entity in order to fix this. If the token has not a compound dependency  append it as a same. In this problem I found the solution trial and error method. I am not sure it is right solution or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NNKBr9o6f8p"
      },
      "source": [
        "Child token should have compound dependency relation with its parent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_EqUbCUmZQt"
      },
      "source": [
        "def seg(sentences_data):\n",
        "  \"\"\"\n",
        "   Parameters\n",
        "    ----------\n",
        "    data : list of sentences. eg.(test_data_sent) \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of Name entities of the sentences.\n",
        "  \"\"\"\n",
        "  hypp=[]\n",
        "  for i in range(len(sentences_data)):\n",
        "    doc=nlp(sentences_data[i])\n",
        "    d=[]\n",
        "    for token in doc:\n",
        "      if (token.ent_type_=='') and (token.dep_=='compound')  and (token.head.ent_type_!=''):\n",
        "        token.ent_type_ = token.head.ent_type_\n",
        "        if (token.i < token.head.i): #check it is same entity with it's head. \n",
        "          d.append((token.text,\"B-\"+replace_values_in_string(token.ent_type_, dic_ne) if token.head.ent_type_ != \"\" else \"O\"))\n",
        "        else:\n",
        "          d.append((token.text, \"I-\"+replace_values_in_string(token.ent_type_, dic_ne) if token.ent_type_ != \"\" else \"O\"))   \n",
        "      else: #use without making change\n",
        "        d.append((token.text,token.ent_iob_ + '-' + replace_values_in_string(token.ent_type_, dic_ne) if token.ent_type_ != \"\" else \"O\"))\n",
        "    hypp.append(d)\n",
        "  return hypp\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofQChSqX1421"
      },
      "source": [
        "hypp=seg(test_data_sent)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ67G5e6_0hD",
        "outputId": "66d99cc7-36ac-48e0-d795-117a9afe22aa"
      },
      "source": [
        "hypp[2]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AL-AIN', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('United', 'B-LOC'),\n",
              " ('Arab', 'I-LOC'),\n",
              " ('Emirates', 'I-LOC'),\n",
              " ('1996-12-06', 'B-MISC')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ija2kcuL_31f",
        "outputId": "2a3b2e03-bf1d-42cb-be30-f04e58a7de8a"
      },
      "source": [
        "ref[2]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AL-AIN', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('United', 'B-LOC'),\n",
              " ('Arab', 'I-LOC'),\n",
              " ('Emirates', 'I-LOC'),\n",
              " ('1996-12-06', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nMcR8eCE02-q",
        "outputId": "bafc5dc9-3096-4929-c2f2-7e902a214b51"
      },
      "source": [
        "results = conll.evaluate(ref, hypp)\n",
        "\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.600</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.422</td>\n",
              "      <td>0.298</td>\n",
              "      <td>0.349</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.093</td>\n",
              "      <td>0.553</td>\n",
              "      <td>0.159</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.746</td>\n",
              "      <td>0.668</td>\n",
              "      <td>0.705</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.352</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.419</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.625  0.577  0.600  1617\n",
              "ORG    0.422  0.298  0.349  1661\n",
              "MISC   0.093  0.553  0.159   702\n",
              "LOC    0.746  0.668  0.705  1668\n",
              "total  0.352  0.519  0.419  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pf0FEmj_c59-",
        "outputId": "fd29bbff-61cf-44dc-cc5b-cbb7d2c273aa"
      },
      "source": [
        "results = conll.evaluate(ref, hyp)\n",
        "\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.724</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.642</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.355</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.094</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.161</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.771</td>\n",
              "      <td>0.668</td>\n",
              "      <td>0.716</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.368</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.430</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.724  0.577  0.642  1617\n",
              "ORG    0.441  0.297  0.355  1661\n",
              "MISC   0.094  0.551  0.161   702\n",
              "LOC    0.771  0.668  0.716  1668\n",
              "total  0.368  0.518  0.430  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zlV1A3S_sp1"
      },
      "source": [
        "As a results, using fix segmentation function, I couldnt get better result. It is almost same with the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149qgHdxzQJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}