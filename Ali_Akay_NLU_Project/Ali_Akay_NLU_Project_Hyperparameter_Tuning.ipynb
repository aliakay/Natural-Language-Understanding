{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see my modelling notebook. This is only used for the hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRV115wZWudo"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import nltk\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H28qvJ4XW9GS",
    "outputId": "6f9ee4a4-21d3-4568-9f34-48896009d43b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uklJRMS-PEve",
    "outputId": "1f0f29c1-594e-4eeb-bea6-541a9892540b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGhg3xJ6S9FI"
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "  with open('ptb.train.txt', encoding = 'utf-8') as f:\n",
    "      raw_text = f.read().replace(\"\\n\", \"<eos>\")\n",
    "      return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "A9XVR9gy_hHC",
    "outputId": "1d8ee453-ff0a-4097-d8cf-8be485edb0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memote'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ptb.train.txt', encoding = 'utf-8') as f:\n",
    "      raw_text = f.read()[:100].replace(\"\\n\", \"<eos>\")\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "sAl3FM1VQCVs",
    "outputId": "e4e015ca-b356-4756-9ba0-fa2bb6433c70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' consumers may want to move their telephones a little closer to the tv set <eos> <unk> <unk> watching ab'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ptb.valid.txt', encoding = 'utf-8') as f:\n",
    "      raw_text = f.read()[:100].replace(\"\\n\", \"<eos>\")\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10vepqPeGt1N"
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "  with open(filename) as f:\n",
    "      raw_text = f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "      return raw_text\n",
    "\n",
    "train_data=read_file('ptb.train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZruq8ubW9D6",
    "outputId": "3be0749e-4b85-41e3-90da-8e07e70a5e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aer',\n",
       " 'banknote',\n",
       " 'berlitz',\n",
       " 'calloway',\n",
       " 'centrust',\n",
       " 'cluett',\n",
       " 'fromstein',\n",
       " 'gitano',\n",
       " 'guterman',\n",
       " 'hydro-quebec',\n",
       " 'ipo',\n",
       " 'kia',\n",
       " 'memotec',\n",
       " 'mlx',\n",
       " 'nahb',\n",
       " 'punts',\n",
       " 'rake',\n",
       " 'regatta',\n",
       " 'rubens',\n",
       " 'sim']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mE2nrp43opyw"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjmiLaLwBVwr"
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size=60,bptt_len=22):\n",
    "  TEXT = data.Field(lower=True,batch_first=True,eos_token=True,unk_token=True,pad_token=True,pad_first=True)\n",
    "  train, val, test = torchtext.legacy.datasets.LanguageModelingDataset.splits(path=\".\", \n",
    "    train=\"ptb.train.txt\", \n",
    "    validation=\"ptb.valid.txt\", \n",
    "    test=\"ptb.test.txt\", \n",
    "    text_field=TEXT)\n",
    "  TEXT.build_vocab(train, max_size=10000)\n",
    "  print(\"vocabulary size: {}\".format(len(TEXT.vocab)))\n",
    "\n",
    "  VOCAB_SIZE = len(TEXT.vocab)\n",
    "  train_iter, val_iter, test_iter = data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=batch_size, bptt_len=bptt_len,device=device,repeat=False, shuffle=True)\n",
    "  return train_iter, val_iter, test_iter\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5ep1ECTO2lK",
    "outputId": "00ef3717-6009-4808-8a7d-31b02c9055c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 10001\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter=get_data(batch_size=60,bptt_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZCcfphZq5Kn"
   },
   "outputs": [],
   "source": [
    "it_test = iter(train_iter)\n",
    "batch = next(it_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxiI-i4_V1y8",
    "outputId": "5005b55f-0167-4745-fcd4-0f2ca8f4c210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.legacy.data.batch.Batch of size 60]\n",
       "\t[.text]:[torch.cuda.LongTensor of size 60x20 (GPU 0)]\n",
       "\t[.target]:[torch.cuda.LongTensor of size 60x20 (GPU 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DVF0rBDq43I",
    "outputId": "abb01015-2dd9-4d75-f373-b3cd767f28be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9971, 9972, 9973, 9975, 9976, 9977, 9981, 9982, 9983, 9984, 9985, 9987,\n",
       "        9988, 9989, 9990, 9992, 9993, 9994, 9995, 9996], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3sxoO0xq4iZ",
    "outputId": "6a3eda1e-585f-4d17-f2c8-2547b2ea878e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9972, 9973, 9975, 9976, 9977, 9981, 9982, 9983, 9984, 9985, 9987, 9988,\n",
       "        9989, 9990, 9992, 9993, 9994, 9995, 9996, 9997], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0kPngYmRNtv",
    "outputId": "bb18b203-20fa-4463-98f9-41bf2a14343a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 10001\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True,batch_first=True,eos_token=True,unk_token=True,pad_token=True,pad_first=True)\n",
    "train, val, test = torchtext.legacy.datasets.LanguageModelingDataset.splits(path=\".\", \n",
    "    train=\"ptb.train.txt\", \n",
    "    validation=\"ptb.valid.txt\", \n",
    "    test=\"ptb.test.txt\", \n",
    "    text_field=TEXT)\n",
    "TEXT.build_vocab(train, max_size=10000)\n",
    "print(\"vocabulary size: {}\".format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSQ_LHaWByMu",
    "outputId": "8bd2ee75-bbe9-4ed8-e2fb-b90f691a451a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 'the', '<unk>', '<eos>', 'n', 'of', 'to', 'a', 'in', 'and']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3ni33hB-Qfh",
    "outputId": "860a721a-2fcb-4ffa-de16-445294124892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim\n",
      "\n",
      "banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food\n"
     ]
    }
   ],
   "source": [
    "it_test = iter(train_iter)\n",
    "batch = next(it_test)\n",
    "print(\" \".join([TEXT.vocab.itos[i] for i in batch.text[0].data])) # where 0 refers to the nth batch\n",
    "print()\n",
    "print(\" \".join([TEXT.vocab.itos[i] for i in batch.target[0].data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Qh7s2utUt3m",
    "outputId": "59cb8444-4cfe-421d-db62-2fc29941e51c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6ZJlAvdIVKR"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "class WordLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_hidden=300,vocab_size=10001, n_layers=2, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.emb_layer = nn.Embedding(vocab_size,250)\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        #self.lr = lr\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(250, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        ## define a dropout layer\n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)\n",
    "        #self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.05\n",
    "        self.emb_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange) \n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        #print(x.shape)\n",
    "\n",
    "        embedded = self.emb_layer(x)\n",
    "        embedded=self.dropout(embedded)\n",
    "        #hidden = self.init_hidden(bs)\n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        #print(out.shape)\n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "\n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "        #print(out.shape) [1200,300]\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "        #print(out.shape) [1200,10001]\n",
    "        #out = self.softmax(out)\n",
    "        return out, hidden\n",
    "      \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))        \n",
    "      \n",
    "        return hidden\n",
    "\n",
    "def repackage_hidden(h):\n",
    "  \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "  if isinstance(h, Variable):\n",
    "    return Variable(h.data)\n",
    "  else:\n",
    "    return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZHzIPhjvbXN"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if torch.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - min_delta\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + min_delta\n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8ADsNv3gK1p"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def idtowordbatch(listofid):\n",
    "  sent=[]\n",
    "  for i in range(19):\n",
    "      a=id_to_word[listofid[i]]\n",
    "      sent.append(a)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPJXzyfbJXt6"
   },
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.exp(cross_entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCTIvBHFJD64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cdOaP1XHzPo"
   },
   "outputs": [],
   "source": [
    "def train(net, data, optimizer ,batch_size=60,clip=0.25,num_steps=20,print_every=256):\n",
    "    # optimize\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    # push model to GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    cumulative_loss = 0.\n",
    "    cumulative_perp=0.\n",
    "    loss = 0\n",
    "    train_loss=0\n",
    "    iters =0\n",
    "    net.train()\n",
    "\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "        \n",
    "    for i, batch in enumerate(data):\n",
    "        inputs, targets = batch.text, batch.target\n",
    "        counter+= 1\n",
    "        inputs = inputs.to(dtype=torch.long)\n",
    "        targets = targets.to(dtype=torch.long)    \n",
    "              # push tensors to GPU\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # detach hidden states\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "        loss = criterion(output, targets.view(-1))\n",
    "            # back-propagate error\n",
    "        loss.backward()\n",
    "        train_loss+= loss.item()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            # update weigths\n",
    "        optimizer.step()\n",
    "            # Resets the gradients\n",
    "        optimizer.zero_grad()  \n",
    "    epoch_train_loss =train_loss / len(data)\n",
    "    train_ppl = np.exp(epoch_train_loss)\n",
    "              \n",
    "    return epoch_train_loss, train_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwN-ff2kEM4n"
   },
   "outputs": [],
   "source": [
    "def test(net,data, batch_size=60, clip=0.25,model_name=\"lm_model\"):\n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    es = EarlyStopping(patience=5)\n",
    "    \n",
    "    # push model to GPU\n",
    "    net.cuda()    \n",
    "    counter = 0\n",
    "    iters=0\n",
    "    valid_loss = 0.\n",
    "    best=np.inf\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    h = net.init_hidden(batch_size)\n",
    "    with torch.no_grad():    \n",
    "      for i, batch in enumerate(data):\n",
    "          inputs, targets = batch.text, batch.target\n",
    "          counter+= 1\n",
    "          inputs = inputs.to(dtype=torch.long)\n",
    "          targets = targets.to(dtype=torch.long)    \n",
    "              # push tensors to GPU\n",
    "          inputs, targets = inputs.cuda(), targets.cuda()\n",
    "              \n",
    "              # detach hidden states\n",
    "          h = tuple([each.data for each in h])\n",
    "          #h = repackage_hidden(h)    \n",
    "              # get the output from the model\n",
    "          output, h = net(inputs, h)\n",
    "              \n",
    "          # calculate the loss and perform backprop\n",
    "          loss = criterion(output, targets.view(-1))\n",
    "          valid_loss += loss.item()\n",
    "          \n",
    "          \n",
    "      epoch_valid_loss = valid_loss / len(data)\n",
    "      valid_ppl = np.exp(epoch_valid_loss)\n",
    "      if valid_loss < best:\n",
    "          best = valid_loss\n",
    "          torch.save(net, model_name+\".pt\")\n",
    "          print(\"model saved.\")\n",
    "      \n",
    "    \n",
    "    \n",
    "    return epoch_valid_loss, valid_ppl                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLPdnu3gg7qB"
   },
   "outputs": [],
   "source": [
    "def find_class(label):\n",
    "  classs=[]\n",
    "  for i in range(len(label)):\n",
    "    a=label[i].tolist()\n",
    "    classs.append(a.index(max(a)))\n",
    "  return classs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrfSyncPVQf0",
    "outputId": "fdbdb389-66af-47e3-faeb-4bd2541e31ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 20])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fg9tzW59mjDd",
    "outputId": "165d97e9-f444-4b7b-cc07-81c80a34d858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 10001\n",
      "<torchtext.legacy.data.iterator.BPTTIterator object at 0x0000020B0977BD00>\n",
      "WordLSTM(\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (emb_layer): Embedding(10002, 250)\n",
      "  (lstm): LSTM(250, 250, num_layers=2, batch_first=True, dropout=0.6)\n",
      "  (fc): Linear(in_features=250, out_features=10002, bias=True)\n",
      ")\n",
      " bptt_len = 10 lr = 0.001 n_hidden = 250 batch_size = 30\n",
      "model saved.\n",
      "Epoch: 1\n",
      "\t Training loss 6.13949, Training perplexity 463.82\n",
      "\t Validation loss 5.73308, Validation perplexity 308.92\n",
      "-----------------------------------------------------\n",
      "model saved.\n",
      "Epoch: 2\n",
      "\t Training loss 5.79260, Training perplexity 327.86\n",
      "\t Validation loss 5.53569, Validation perplexity 253.58\n",
      "-----------------------------------------------------\n",
      "After training:\n",
      "model saved.\n",
      "model saved.\n",
      "\t Validation loss 5.53569, Validation perplexity 253.58\n",
      "\t Test loss 5.48296, Test perplexity 240.56\n",
      "-----------------------------------------------------\n",
      "graph(%self.1 : __torch__.WordLSTM,\n",
      "      %input.1 : Long(30, 10, strides=[10, 1], requires_grad=0, device=cuda:0),\n",
      "      %27 : (Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=0, device=cuda:0), Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=0, device=cuda:0))):\n",
      "  %122 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
      "  %119 : __torch__.torch.nn.modules.rnn.LSTM = prim::GetAttr[name=\"lstm\"](%self.1)\n",
      "  %110 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%self.1)\n",
      "  %109 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"emb_layer\"](%self.1)\n",
      "  %hx.1 : Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=0, device=cuda:0), %hx : Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=0, device=cuda:0) = prim::TupleUnpack(%27)\n",
      "  %140 : bool = prim::Constant[value=0](), scope: __module.emb_layer # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n",
      "  %141 : int = prim::Constant[value=-1](), scope: __module.emb_layer # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n",
      "  %142 : Tensor = prim::GetAttr[name=\"weight\"](%109)\n",
      "  %input.2 : Float(30, 10, 250, strides=[2500, 250, 1], requires_grad=1, device=cuda:0) = aten::embedding(%142, %input.1, %141, %140, %140), scope: __module.emb_layer # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n",
      "  %144 : bool = prim::Constant[value=0](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %145 : float = prim::Constant[value=0.59999999999999998](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %input.3 : Float(30, 10, 250, strides=[2500, 250, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.2, %145, %144), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %147 : bool = prim::Constant[value=0](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %148 : float = prim::Constant[value=0.59999999999999998](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %149 : int = prim::Constant[value=2](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %150 : bool = prim::Constant[value=1](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %151 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%119)\n",
      "  %152 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%119)\n",
      "  %153 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%119)\n",
      "  %154 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%119)\n",
      "  %155 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%119)\n",
      "  %156 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%119)\n",
      "  %157 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%119)\n",
      "  %158 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%119)\n",
      "  %159 : Tensor[] = prim::ListConstruct(%hx.1, %hx), scope: __module.lstm\n",
      "  %160 : Tensor[] = prim::ListConstruct(%158, %157, %156, %155, %154, %153, %152, %151), scope: __module.lstm\n",
      "  %input.4 : Float(30, 10, 250, strides=[250, 7500, 1], requires_grad=1, device=cuda:0), %162 : Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0), %163 : Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0) = aten::lstm(%input.3, %159, %160, %150, %149, %148, %147, %147, %150), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %164 : (Float(30, 10, 250, strides=[250, 7500, 1], requires_grad=1, device=cuda:0), Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0), Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0)) = prim::TupleConstruct(%input.4, %162, %163)\n",
      "  %132 : Float(30, 10, 250, strides=[250, 7500, 1], requires_grad=1, device=cuda:0), %133 : Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0), %134 : Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0) = prim::TupleUnpack(%164)\n",
      "  %165 : bool = prim::Constant[value=0](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %166 : float = prim::Constant[value=0.59999999999999998](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %lstm_output : Float(30, 10, 250, strides=[250, 7500, 1], requires_grad=1, device=cuda:0) = aten::dropout(%132, %166, %165), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %93 : int = prim::Constant[value=-1]() # <ipython-input-21-4b35a526bf28>:46:0\n",
      "  %94 : int = prim::Constant[value=250]() # <ipython-input-21-4b35a526bf28>:46:0\n",
      "  %95 : int[] = prim::ListConstruct(%93, %94)\n",
      "  %input : Float(300, 250, strides=[250, 1], requires_grad=1, device=cuda:0) = aten::reshape(%lstm_output, %95) # <ipython-input-21-4b35a526bf28>:46:0\n",
      "  %168 : int = prim::Constant[value=1](), scope: __module.fc # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %169 : Tensor = prim::GetAttr[name=\"bias\"](%122)\n",
      "  %170 : Tensor = prim::GetAttr[name=\"weight\"](%122)\n",
      "  %171 : Float(250, 10002, strides=[1, 250], requires_grad=1, device=cuda:0) = aten::t(%170), scope: __module.fc # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %172 : Float(300, 10002, strides=[10002, 1], requires_grad=1, device=cuda:0) = aten::addmm(%169, %input, %171, %168, %168), scope: __module.fc # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %101 : (Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0), Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0)) = prim::TupleConstruct(%133, %134)\n",
      "  %102 : (Float(300, 10002, strides=[10002, 1], requires_grad=1, device=cuda:0), (Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0), Float(2, 30, 250, strides=[7500, 250, 1], requires_grad=1, device=cuda:0))) = prim::TupleConstruct(%172, %101)\n",
      "  return (%102)\n",
      "\n",
      "vocabulary size: 10001\n",
      "<torchtext.legacy.data.iterator.BPTTIterator object at 0x0000020B988FFF70>\n",
      "WordLSTM(\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (emb_layer): Embedding(10002, 250)\n",
      "  (lstm): LSTM(250, 250, num_layers=2, batch_first=True, dropout=0.6)\n",
      "  (fc): Linear(in_features=250, out_features=10002, bias=True)\n",
      ")\n",
      " bptt_len = 10 lr = 0.001 n_hidden = 250 batch_size = 40\n",
      "model saved.\n",
      "Epoch: 1\n",
      "\t Training loss 6.15257, Training perplexity 469.92\n",
      "\t Validation loss 5.73618, Validation perplexity 309.88\n",
      "-----------------------------------------------------\n",
      "model saved.\n",
      "Epoch: 2\n",
      "\t Training loss 5.77641, Training perplexity 322.60\n",
      "\t Validation loss 5.52426, Validation perplexity 250.70\n",
      "-----------------------------------------------------\n",
      "After training:\n",
      "model saved.\n",
      "model saved.\n",
      "\t Validation loss 5.52426, Validation perplexity 250.70\n",
      "\t Test loss 5.47468, Test perplexity 238.58\n",
      "-----------------------------------------------------\n",
      "graph(%self.1 : __torch__.___torch_mangle_9.WordLSTM,\n",
      "      %input.1 : Long(40, 10, strides=[10, 1], requires_grad=0, device=cuda:0),\n",
      "      %27 : (Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=0, device=cuda:0), Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=0, device=cuda:0))):\n",
      "  %122 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
      "  %119 : __torch__.torch.nn.modules.rnn.___torch_mangle_7.LSTM = prim::GetAttr[name=\"lstm\"](%self.1)\n",
      "  %110 : __torch__.torch.nn.modules.dropout.___torch_mangle_5.Dropout = prim::GetAttr[name=\"dropout\"](%self.1)\n",
      "  %109 : __torch__.torch.nn.modules.sparse.___torch_mangle_6.Embedding = prim::GetAttr[name=\"emb_layer\"](%self.1)\n",
      "  %hx.1 : Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=0, device=cuda:0), %hx : Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=0, device=cuda:0) = prim::TupleUnpack(%27)\n",
      "  %140 : bool = prim::Constant[value=0](), scope: __module.emb_layer # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n",
      "  %141 : int = prim::Constant[value=-1](), scope: __module.emb_layer # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n",
      "  %142 : Tensor = prim::GetAttr[name=\"weight\"](%109)\n",
      "  %input.2 : Float(40, 10, 250, strides=[2500, 250, 1], requires_grad=1, device=cuda:0) = aten::embedding(%142, %input.1, %141, %140, %140), scope: __module.emb_layer # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n",
      "  %144 : bool = prim::Constant[value=0](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %145 : float = prim::Constant[value=0.59999999999999998](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %input.3 : Float(40, 10, 250, strides=[2500, 250, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.2, %145, %144), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %147 : bool = prim::Constant[value=0](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %148 : float = prim::Constant[value=0.59999999999999998](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %149 : int = prim::Constant[value=2](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %150 : bool = prim::Constant[value=1](), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %151 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%119)\n",
      "  %152 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%119)\n",
      "  %153 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%119)\n",
      "  %154 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%119)\n",
      "  %155 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%119)\n",
      "  %156 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%119)\n",
      "  %157 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%119)\n",
      "  %158 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%119)\n",
      "  %159 : Tensor[] = prim::ListConstruct(%hx.1, %hx), scope: __module.lstm\n",
      "  %160 : Tensor[] = prim::ListConstruct(%158, %157, %156, %155, %154, %153, %152, %151), scope: __module.lstm\n",
      "  %input.4 : Float(40, 10, 250, strides=[250, 10000, 1], requires_grad=1, device=cuda:0), %162 : Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0), %163 : Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0) = aten::lstm(%input.3, %159, %160, %150, %149, %148, %147, %147, %150), scope: __module.lstm # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:661:0\n",
      "  %164 : (Float(40, 10, 250, strides=[250, 10000, 1], requires_grad=1, device=cuda:0), Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0), Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0)) = prim::TupleConstruct(%input.4, %162, %163)\n",
      "  %132 : Float(40, 10, 250, strides=[250, 10000, 1], requires_grad=1, device=cuda:0), %133 : Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0), %134 : Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0) = prim::TupleUnpack(%164)\n",
      "  %165 : bool = prim::Constant[value=0](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %166 : float = prim::Constant[value=0.59999999999999998](), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %lstm_output : Float(40, 10, 250, strides=[250, 10000, 1], requires_grad=1, device=cuda:0) = aten::dropout(%132, %166, %165), scope: __module.dropout # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %93 : int = prim::Constant[value=-1]() # <ipython-input-21-4b35a526bf28>:46:0\n",
      "  %94 : int = prim::Constant[value=250]() # <ipython-input-21-4b35a526bf28>:46:0\n",
      "  %95 : int[] = prim::ListConstruct(%93, %94)\n",
      "  %input : Float(400, 250, strides=[250, 1], requires_grad=1, device=cuda:0) = aten::reshape(%lstm_output, %95) # <ipython-input-21-4b35a526bf28>:46:0\n",
      "  %168 : int = prim::Constant[value=1](), scope: __module.fc # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %169 : Tensor = prim::GetAttr[name=\"bias\"](%122)\n",
      "  %170 : Tensor = prim::GetAttr[name=\"weight\"](%122)\n",
      "  %171 : Float(250, 10002, strides=[1, 250], requires_grad=1, device=cuda:0) = aten::t(%170), scope: __module.fc # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %172 : Float(400, 10002, strides=[10002, 1], requires_grad=1, device=cuda:0) = aten::addmm(%169, %input, %171, %168, %168), scope: __module.fc # C:\\Users\\merta\\anaconda3\\envs\\aisenv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %101 : (Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0), Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0)) = prim::TupleConstruct(%133, %134)\n",
      "  %102 : (Float(400, 10002, strides=[10002, 1], requires_grad=1, device=cuda:0), (Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0), Float(2, 40, 250, strides=[10000, 250, 1], requires_grad=1, device=cuda:0))) = prim::TupleConstruct(%172, %101)\n",
      "  return (%102)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "def log_values(writer, step, loss, perplexity, prefix):\n",
    "  writer.add_scalar(f\"{prefix}/loss\", loss, step)\n",
    "  writer.add_scalar(f\"{prefix}/perplexity\", perplexity, step)\n",
    "\n",
    "# Hyperparameters\n",
    "parameters = dict(\n",
    "    lr = [0.001,0.005,0.01]\n",
    "    bptt_len = [20 30,40]\n",
    "    n_hidden = [300,350,400]\n",
    "    batch_size = [30,45,60]\n",
    ")\n",
    "param_values = [v for v in parameters.values()]\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "for run_id, (lr,bptt_len, n_hidden,batch_size) in enumerate(product(*param_values)):\n",
    "  # Creates a logger for the experiment\n",
    "  \n",
    "  comment = f' bptt_len = {bptt_len} lr = {lr} n_hidden = {n_hidden} batch_size = {batch_size}'\n",
    "  writer = SummaryWriter(comment=comment)\n",
    "  #Get Data\n",
    "  train_iter, val_iter, test_iter=get_data(batch_size=batch_size,bptt_len=bptt_len)\n",
    "  print(train_iter)\n",
    "  it_test = iter(train_iter)\n",
    "  batch = next(it_test)\n",
    "  # instantiate the model\n",
    "  net = WordLSTM(n_hidden=n_hidden,vocab_size=10002, n_layers=2, drop_prob=0.6)\n",
    "  h = net.init_hidden(batch_size)\n",
    "  #h=torch.tensor(h)\n",
    "  net.cuda()\n",
    "  print(net)\n",
    "  print(comment)\n",
    "  optimizer = torch.optim.RMSprop(net.parameters(), lr=lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "  opt = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "  es = EarlyStopping(patience=5)\n",
    "  for e in range(2):\n",
    "\n",
    "    train_loss, train_perplexity = train(net,train_iter,optimizer=optimizer,batch_size = batch_size)\n",
    "    val_loss, valid_perplexity = test(net,val_iter,batch_size =batch_size,model_name=\"lm_model\"+str(run_id))\n",
    "    # Logs to TensorBoard\n",
    "    if es.step(torch.from_numpy(np.array([val_loss]))):\n",
    "          break\n",
    "    log_values(writer, e, train_loss, train_perplexity, \"Train\")\n",
    "    log_values(writer, e, val_loss, valid_perplexity, \"Validation\")\n",
    "\n",
    "    print('Epoch: {:d}'.format(e+1))\n",
    "    print('\\t Training loss {:.5f}, Training perplexity {:.2f}'.format(train_loss, train_perplexity))\n",
    "    print('\\t Validation loss {:.5f}, Validation perplexity {:.2f}'.format(val_loss, valid_perplexity))\n",
    "    print('-----------------------------------------------------')\n",
    "\n",
    "  # Compute final evaluation results\n",
    "  print('After training:')\n",
    "  #train_loss, train_perplexity = test(net,train_iter ,batch_size = batch_size)\n",
    "  val_loss, valid_perplexity = test(net,val_iter ,batch_size = batch_size)\n",
    "  test_loss, test_perplexity = test(net,test_iter ,batch_size = batch_size)\n",
    "\n",
    "  # Logs to TensorBoard\n",
    "  log_values(writer, e+1, train_loss, train_perplexity, \"Train\")\n",
    "  log_values(writer, e+1, val_loss, valid_perplexity, \"Validation\")\n",
    "  #log_values(writer, e+1, test_loss, test_perplexity, \"Test\")\n",
    "\n",
    "  #print('\\t Training loss {:.5f}, Training perplexity {:.2f}'.format(train_loss, train_perplexity))\n",
    "  print('\\t Validation loss {:.5f}, Validation perplexity {:.2f}'.format(val_loss, valid_perplexity))\n",
    "  print('\\t Test loss {:.5f}, Test perplexity {:.2f}'.format(test_loss, test_perplexity))\n",
    "  print('-----------------------------------------------------')\n",
    "\n",
    "  writer.add_hparams(\n",
    "            {\"lr\": lr, \"bptt_len\": bptt_len, \"n_hidden\":n_hidden,\"batch_size\":batch_size},\n",
    "            {\n",
    "                \"test_perplexity\": test_perplexity,\n",
    "                \"test_loss\": test_loss,\n",
    "            }\n",
    "        )\n",
    "  inputs = iter(train_iter)\n",
    "  inputs=next(inputs)\n",
    "  net.lstm.all_weights\n",
    "  writer.add_graph(net,(inputs.text,h),verbose=True)\n",
    "  writer.add_histogram('lstm.hidden-hidden.weight0', net.lstm.weight_hh_l0, e)\n",
    "  writer.add_histogram('conv1.hidden-hidden.weight1', net.lstm.weight_hh_l1, e)\n",
    "  writer.add_histogram('conv1.input-hidden.weight0', net.lstm.weight_ih_l0, e)\n",
    "  writer.add_histogram('conv1.input-hidden.weight1', net.lstm.weight_ih_l1, e)\n",
    "  writer.add_histogram('conv1.hidden-hidden.bias0', net.lstm.bias_hh_l0, e)\n",
    "  writer.add_histogram('conv1.hidden-hidden.bias1', net.lstm.bias_hh_l1, e)\n",
    "  writer.add_histogram('conv1.input-hidden.bias0', net.lstm.bias_ih_l0, e)\n",
    "  writer.add_histogram('conv1.input-hidden.bias1', net.lstm.bias_ih_l1, e)\n",
    "\n",
    "  # Closes the logger\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5C0JkUdyPEvz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8zeWvW1S5Up"
   },
   "outputs": [],
   "source": [
    "!tensorboard dev upload \\\n",
    "  --logdir \\runs \\\n",
    "  --name \"(optional) My latest experiment\" \\\n",
    "  --description \"(optional) Simple comparison of several hyperparameters\" \\\n",
    "  --one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AIXWL8o5la1"
   },
   "source": [
    "Please go to https://tensorboard.dev/experiment/KuKeRDFaTa2dntoswT21gQ/#scalars link to see the hyperparameter tuning results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRfsUON9PEv0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ali Akay NLU Project Hyperparameter Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
