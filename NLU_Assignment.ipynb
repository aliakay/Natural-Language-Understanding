{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVJsHj1lzTFC"
      },
      "source": [
        "## Trento University master of Artificial Intelligence Systems - Natural Language Understanding Course First Assignment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-lTqR090Mtf"
      },
      "source": [
        "\n",
        "\n",
        "*   Student Name: Ali Akay\n",
        "*   Course: Natural Language Understanding\n",
        "*   Professor: Giuseppe Riccardi\n",
        "*   Lab: https://github.com/esrel/NLU.Lab.2021\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j1EXCzT3Cz1"
      },
      "source": [
        "**Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zhhtUtaAfu4"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "nlp = spacy.load('en')\n",
        "import nltk\n",
        "from nltk import Tree"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMH70JlQ3PN1"
      },
      "source": [
        "**Exercise 1:** For the first exercise the *dep_path* function is used.This function extract the dependancy path for every word starting from ROOT. *Token.text* gives us the token and *span.root* gives us the ROOT of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoRi6Jtnx3os"
      },
      "source": [
        "def dep_path(sentence):\n",
        "  \"\"\"\n",
        "  This function extract the dependancy path starting from ROOT.\n",
        "  sentence --> string\n",
        "  \"\"\"\n",
        "  doc = nlp(sentence)\n",
        "  doc_p = nlp.parser(doc)\n",
        "  span=doc[0:]\n",
        "  paths = []\n",
        "  for token in doc:\n",
        "    path_t = []\n",
        "    while token != span.root:\n",
        "      path_t.insert(0, token.text)   \n",
        "      token = token.head\n",
        "    path_t.insert(0, token.text)     \n",
        "    path_t.insert(0, \"ROOT\")\n",
        "    paths.append(path_t) \n",
        "  return paths\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwipq87I5IZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuTkIHno5JOz"
      },
      "source": [
        "**Exercises 2-3:** The subtree of a token is the token itself and all its descendants nodes. Dependency Tree is created with *to_nltk_tree()* function.After that,to find the subtree of a token *token.subtree* is used. Then list of subtrees created and checked with the example list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToA7bs1OyhqV"
      },
      "source": [
        "def subtree_check(sentences):\n",
        "  \"\"\"\n",
        "  This function checks if a given list of tokens forms a subtree\n",
        "  sentence --> string\n",
        "  \"\"\"\n",
        "  subtree_df=[]\n",
        "  doc = nlp(sentences)\n",
        "  doc_p = nlp.parser(doc)\n",
        "  for token in doc_p:  \n",
        "      subtree_df.append([t.text for t in token.subtree]) #extract all subtrees in list\n",
        "  given_listoftoken=input(\"Enter list of word 'eg= Credit and mortgage'  : \")\n",
        "  given_listoftoken=(given_listoftoken)\n",
        "  given_listoftoken=nlp(given_listoftoken)\n",
        "  a=[token.text for token in given_listoftoken] #check given list of token is in the subtree list\n",
        "  print(\"Is given token form of subset? True/False:\",a in subtree_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI0svhd4ykEC"
      },
      "source": [
        "def to_nltk_tree(node):\n",
        "  \"\"\"\n",
        "  Dependency Tree\n",
        "  \"\"\"\n",
        "    if node.n_lefts + node.n_rights > 0:\n",
        "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
        "    else:\n",
        "        return node.orth_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1SCxijW60Lf"
      },
      "source": [
        "Exercise 4:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vVEZF665D4"
      },
      "source": [
        "**Exercise 4:** head() function is used to return head of span. Basically we have to give a sentence and the function makes it span then head of span can find easily with *span.root*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTFNxIo3y5yt"
      },
      "source": [
        "def head(sentences):\n",
        "  \"\"\"\n",
        "  This function gives the head of span\n",
        "  \"\"\"\n",
        "  doc = nlp(sentences)\n",
        "  doc_p =nlp.parser(doc)\n",
        "  span = doc[0:] #doc to span\n",
        "  print(\"Head of Span: \",span.root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyCDITNf7luk"
      },
      "source": [
        "**Exercise 5:** *dep_* give us the dependency of the word. In this exercise the function extract if it has *subject*, *direct object* and *indirect object*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXttkehUAVmw"
      },
      "source": [
        "\n",
        "def extract_sub_obj(sentences):\n",
        "  doc = nlp(sentences)\n",
        "  doc_p =nlp.parser(doc)\n",
        "  nsubj=[]\n",
        "  dobj=[]\n",
        "  iobj=[]\n",
        "  for token in doc:\n",
        "    if(token.dep_ == 'nsubj'):\n",
        "      nsubj.append(token.text)\n",
        "    elif(token.dep_ == 'dobj'):\n",
        "      dobj.append(token.text)\n",
        "    elif(token.dep_ == 'iobj'):\n",
        "      iobj.append(token.text)\n",
        "\n",
        "  print(\"nsubj: \",nsubj)\n",
        "  print(\"dobj: \",dobj)\n",
        "  print(\"iobj: \",iobj)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99mYFhk3AZew"
      },
      "source": [
        "def main():\n",
        "  \"\"\"\n",
        "  Required a sentence. Example: Credit and mortgage account holders must submit their requests.\n",
        "  \"\"\"\n",
        "\n",
        "  text=input(\"Please Enter a sentence: \")\n",
        "  print(\"      \")\n",
        "  doc = nlp(text)\n",
        "  doc_p = nlp.parser(doc)\n",
        "  print(\"------------Lemma-----------\")\n",
        "  print(\"      \")\n",
        "  print([token.lemma_ for token in doc_p])\n",
        "  print(\"      \")\n",
        "  print(\"------------Token Analysis-----------\")\n",
        "  print(\"      \")\n",
        "  for token in doc_p:  \n",
        "      print(\"Text-->\",token.text, \"/POS-->\", token.pos_, \"/DEP-->\",token.dep_)\n",
        "  print(\"      \")\n",
        "  print(\"------------Tree-----------\")\n",
        "  print(\"      \")     \n",
        "  [to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
        "  print(\"      \")\n",
        "  print(\"------------Dependency Path-----------\")\n",
        "  print(\"      \")    \n",
        "  print(dep_path(text))\n",
        "  print(\"      \")  \n",
        "  print(\"------------SubTree-----------\")\n",
        "  for token in doc_p:  \n",
        "    print(\"Text: \",token.text,\"--- Subtrees: \",[t.text for t in token.subtree])    \n",
        "  print(\"      \")\n",
        "  print(\"----------Check ----------\")\n",
        "  print(\"      \")\n",
        "  subtree_check(text)\n",
        "  print(\"      \")\n",
        "  print(\"----------Span ----------\")\n",
        "  print(\"      \")\n",
        "  head(text)\n",
        "  print(\"----------Extract to Subjects and Objects ----------\")\n",
        "  extract_sub_obj(text)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JPjb-QbAbZw",
        "outputId": "62b6b6c9-e0be-4e8b-ffea-1f0014f3515e"
      },
      "source": [
        "main()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please Enter a sentence: Credit and mortgage account holders must submit their requests.\n",
            "      \n",
            "------------Lemma-----------\n",
            "      \n",
            "['credit', 'and', 'mortgage', 'account', 'holder', 'must', 'submit', '-PRON-', 'request', '.']\n",
            "      \n",
            "------------Token Analysis-----------\n",
            "      \n",
            "Text--> Credit /POS--> NOUN /DEP--> nmod\n",
            "Text--> and /POS--> CCONJ /DEP--> cc\n",
            "Text--> mortgage /POS--> NOUN /DEP--> conj\n",
            "Text--> account /POS--> NOUN /DEP--> compound\n",
            "Text--> holders /POS--> NOUN /DEP--> nsubj\n",
            "Text--> must /POS--> VERB /DEP--> aux\n",
            "Text--> submit /POS--> VERB /DEP--> ROOT\n",
            "Text--> their /POS--> DET /DEP--> poss\n",
            "Text--> requests /POS--> NOUN /DEP--> dobj\n",
            "Text--> . /POS--> PUNCT /DEP--> punct\n",
            "      \n",
            "------------Tree-----------\n",
            "      \n",
            "         submit                          \n",
            "  _________|________________________      \n",
            " |    |         holders             |    \n",
            " |    |            |                |     \n",
            " |    |         account             |    \n",
            " |    |            |                |     \n",
            " |    |          Credit          requests\n",
            " |    |     _______|_______         |     \n",
            "must  .   and           mortgage  their  \n",
            "\n",
            "      \n",
            "------------Dependency Path-----------\n",
            "      \n",
            "[['ROOT', 'submit', 'holders', 'account', 'Credit'], ['ROOT', 'submit', 'holders', 'account', 'Credit', 'and'], ['ROOT', 'submit', 'holders', 'account', 'Credit', 'mortgage'], ['ROOT', 'submit', 'holders', 'account'], ['ROOT', 'submit', 'holders'], ['ROOT', 'submit', 'must'], ['ROOT', 'submit'], ['ROOT', 'submit', 'requests', 'their'], ['ROOT', 'submit', 'requests'], ['ROOT', 'submit', '.']]\n",
            "      \n",
            "------------SubTree-----------\n",
            "Text:  Credit --- Subtrees:  ['Credit', 'and', 'mortgage']\n",
            "Text:  and --- Subtrees:  ['and']\n",
            "Text:  mortgage --- Subtrees:  ['mortgage']\n",
            "Text:  account --- Subtrees:  ['Credit', 'and', 'mortgage', 'account']\n",
            "Text:  holders --- Subtrees:  ['Credit', 'and', 'mortgage', 'account', 'holders']\n",
            "Text:  must --- Subtrees:  ['must']\n",
            "Text:  submit --- Subtrees:  ['Credit', 'and', 'mortgage', 'account', 'holders', 'must', 'submit', 'their', 'requests', '.']\n",
            "Text:  their --- Subtrees:  ['their']\n",
            "Text:  requests --- Subtrees:  ['their', 'requests']\n",
            "Text:  . --- Subtrees:  ['.']\n",
            "      \n",
            "----------Check ----------\n",
            "      \n",
            "Enter list of word 'eg= Credit and mortgage'  : Credit and mortgage\n",
            "Given token form of subset True/False: True\n",
            "      \n",
            "----------Span ----------\n",
            "      \n",
            "Head of Span:  submit\n",
            "----------Extract to Subjects and Objects ----------\n",
            "nsubj:  ['holders']\n",
            "dobj:  ['requests']\n",
            "iobj:  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm5b7qARAozD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}